<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>LoRA on an 8GB GPU — Thesis Study</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta
    name="description"
    content="MS thesis project on parameter-efficient fine-tuning (LoRA) under strict 8 GB GPU constraints."
  />
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <div class="page">

    <!-- Top bar -->
    <header class="nav">
      <div class="nav-title">LoRA on an 8GB GPU</div>
      <div class="nav-tag">Thesis study</div>
    </header>

    <!-- Main content -->
    <main class="main">

      <!-- Hero -->
      <section class="hero">
        <div class="badge-row">
          <span class="badge">LoRA / QLoRA</span>
          <span class="badge">8 GB GPU constraints</span>
          <span class="badge">MS thesis</span>
        </div>

        <h1 class="hero-title">LoRA on an 8&nbsp;GB GPU — Thesis Study</h1>
        <p class="hero-subtitle">
          MS thesis project on parameter-efficient fine-tuning (LoRA) under strict 8&nbsp;GB GPU constraints.
        </p>
        <p class="hero-note">
          This page is a human-readable overview of the study design, tracks, and funding context. It links out to
          plans, drafts, and experiments.
        </p>
      </section>

      <!-- Study Focus + Tracks -->
      <section class="section-grid">
        <div class="section-card">
          <div class="meta-label">Study Focus</div>
          <p class="meta-block">
            The core study evaluates how LoRA behaves when training and serving models on an 8&nbsp;GB GPU. It examines
            three experimental tracks plus a fourth workflow/cost track.
          </p>

          <div class="details-group" style="margin-top: 1rem;">

            <!-- Track 1 -->
            <details open>
              <summary>
                <span class="summary-label">
                  <span class="summary-tag">Track&nbsp;1</span>
                  <span>Text model adaptation</span>
                </span>
                <span class="chevron">▶</span>
              </summary>
              <div class="details-body">
                <p>Small LLMs fine-tuned with LoRA / QLoRA, measuring:</p>
                <ul>
                  <li>Task performance (e.g., eval accuracy)</li>
                  <li>Throughput (tokens/sec)</li>
                  <li>Memory behavior (VRAM usage, paging)</li>
                </ul>
              </div>
            </details>

            <!-- Track 2 -->
            <details>
              <summary>
                <span class="summary-label">
                  <span class="summary-tag">Track&nbsp;2</span>
                  <span>Vision model adaptation</span>
                </span>
                <span class="chevron">▶</span>
              </summary>
              <div class="details-body">
                <p>ViT-tiny–scale models trained with LoRA / DoRA:</p>
                <ul>
                  <li>Rank/placement tradeoffs</li>
                  <li>Accuracy vs parameter budget</li>
                  <li>Throughput and memory usage</li>
                </ul>
              </div>
            </details>

            <!-- Track 3 -->
            <details>
              <summary>
                <span class="summary-label">
                  <span class="summary-tag">Track&nbsp;3</span>
                  <span>Multi-adapter serving</span>
                </span>
                <span class="chevron">▶</span>
              </summary>
              <div class="details-body">
                <p>Evaluates serving many task-specific LoRA adapters:</p>
                <ul>
                  <li>Merged vs unmerged adapters</li>
                  <li>Latency + time-to-first-token</li>
                  <li>Memory footprint for shared base model</li>
                </ul>
              </div>
            </details>

          </div>
        </div>

        <!-- Quick facts -->
        <aside class="section-card">
          <div class="meta-label">Quick facts</div>
          <div class="meta-block">
            <strong>Hardware:</strong> single 8&nbsp;GB GPU<br />
            <strong>Methods:</strong> LoRA-family PEFT<br />
            <strong>Scope:</strong> text + vision + serving
            <div class="meta-pill-row">
              <span class="meta-pill">Resource-constrained</span>
              <span class="meta-pill">GPU efficiency</span>
              <span class="meta-pill">Adapter serving</span>
            </div>
          </div>
        </aside>
      </section>

      <!-- 4th Track + Funding -->
      <section class="section-grid">
        <div class="section-card">
          <div class="meta-label">4th track</div>

          <details open>
            <summary>
              <span class="summary-label">
                <span class="summary-tag">Track&nbsp;4</span>
                <span>Workflow, cost, and process</span>
              </span>
              <span class="chevron">▶</span>
            </summary>

            <div class="details-body">
              <p>Focuses on the training workflow itself:</p>
              <ul>
                <li>Local 8&nbsp;GB GPU vs cloud compute</li>
                <li>Time, energy, cost-per-token metrics</li>
                <li>Lifecycle: local → cloud → deployment</li>
              </ul>
            </div>
          </details>
        </div>

        <aside class="section-card">
          <div class="meta-label">Funding</div>
          <div class="meta-block">
            <p>The project includes <strong>$150 Tinker compute credits</strong> for cloud experiments.</p>
            <p>These credits either:</p>
            <ul>
              <li>Fund a focused burst of LoRA trials, or</li>
              <li>Seed extended workflow/cost analysis.</li>
            </ul>
          </div>
        </aside>
      </section>

      <!-- Interactive Chart -->
      <section class="section-card" style="margin-top: 2.3rem;">
        <div class="meta-label">LoRA Trade-off Explorer</div>
        <p class="meta-block">Move the slider to explore how LoRA rank affects accuracy, VRAM usage, and throughput.</p>

        <div style="margin-top: 1.5rem;">
          <input id="rankSlider" type="range" min="1" max="64" value="8" step="1" style="width: 100%;" />
          <p style="text-align: center; margin-top: 0.5rem;">
            Rank: <span id="rankValue">8</span>
          </p>
        </div>

        <canvas id="loraChart" height="120" style="margin-top: 1.5rem;"></canvas>
      </section>

    </main>

    <!-- Footer -->
    <footer class="footer">
      LoRA on an 8&nbsp;GB GPU — MS thesis study overview. This site is evolving as the research progresses.
    </footer>

  </div>

  <!-- Chart.js + slider logic -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script>
    const ctx = document.getElementById('loraChart').getContext('2d');

    // Example synthetic data (replace with real measurements if desired)
    const loraData = {};
    for (let r = 1; r <= 64; r++) {
      loraData[r] = {
        accuracy: 0.55 + Math.log(r) * 0.05,
        vram: 2.2 + r * 0.02,
        throughput: 310 - r * 2.5
      };
    }

    const chart = new Chart(ctx, {
      type: 'line',
      data: {
        labels: ['Accuracy', 'VRAM (GB)', 'Throughput (tok/s)'],
        datasets: [{
          label: 'LoRA Metrics',
          data: [0, 0, 0],
          borderColor: 'rgba(96,165,250,1)',
          backgroundColor: 'rgba(96,165,250,0.3)',
          tension: 0.3,
          fill: true
        }]
      },
      options: { scales: { y: { beginAtZero: false } } }
    });

    const slider = document.getElementById('rankSlider');
    const rankValue = document.getElementById('rankValue');

    function updateChart(rank) {
      const m = loraData[rank];
      chart.data.datasets[0].data = [
        m.accuracy.toFixed(3),
        m.vram.toFixed(2),
        m.throughput.toFixed(1)
      ];
      chart.update();
    }

    slider.addEventListener('input', () => {
      rankValue.textContent = slider.value;
      updateChart(slider.value);
    });

    updateChart(8);
  </script>

</body>
</html>
